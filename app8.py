import os
import io
import streamlit as st
from PIL import Image
import torch
from facenet_pytorch import MTCNN, InceptionResnetV1
import pickle
import uuid
import base64
import tempfile

# Generar un ID √∫nico utilizando uuid
unique_id = str(uuid.uuid4())[:8]

class FaceNetModels:
    def __init__(self):
        self.model = InceptionResnetV1(pretrained="vggface2").eval()
        self.mtcnn = MTCNN(min_face_size=50, keep_all=False)
        self.caracteristicas = None

    def load_caracteristicas(self, filename):
        with open(filename, "rb") as f:
            self.caracteristicas = pickle.load(f)

    def embedding(self, img_tensor):
        img_embedding = self.model(img_tensor.unsqueeze(0))
        return img_embedding

    def Distancia(self, img_embedding):
        distances = [
            (label, torch.dist(emb, img_embedding))
            for label, emb in self.caracteristicas.items()
        ]
        sorted_distances = sorted(distances, key=lambda x: x[1])
        return sorted_distances[0][0], sorted_distances[0][1].item()

    def extract_embeddings(self, uploaded_files):
        embeddings_list = []
        labels = []
        no_process_images = []

        for uploaded_file in uploaded_files:
            # Usar bytes directamente en lugar de abrir como archivo
            img = Image.open(uploaded_file)
            img = img.convert("RGB")
            label = os.path.splitext(uploaded_file.name)[0]
            face = self.mtcnn(img)

            if face is None:
                no_process_images.append(uploaded_file.name)
                continue

            embeddings_list.append(self.model(face.unsqueeze(0)))
            labels.append(label)

        self.caracteristicas = dict(zip(labels, embeddings_list))
        st.write(f"Se procesaron {len(embeddings_list)} im√°genes.")

        if no_process_images:
            st.warning(f"No se pudieron procesar {len(no_process_images)} im√°genes: {', '.join(no_process_images)}")

        return self.caracteristicas

def feature_extraction(uploaded_files):
    if not uploaded_files:
        st.warning("Por favor, carga al menos una imagen para extraer caracter√≠sticas.")
        return
    
    _models = FaceNetModels()
    if st.button("Extraer caracter√≠sticas", type="primary"):
        try:
            with st.spinner("Procesando im√°genes..."):
                caracteristicas = _models.extract_embeddings(uploaded_files)
                
            if not caracteristicas:
                st.error("No se pudieron procesar las im√°genes. Verifica que contengan rostros detectables.")
                return
                
            filename = f"feature_{unique_id}.pkl"

            # Crear el archivo en memoria
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pkl") as tmp_file:
                pickle.dump(caracteristicas, tmp_file)
                tmp_file.flush()
                
                # Leer el archivo para crear el download
                with open(tmp_file.name, "rb") as f:
                    pickle_data = f.read()
                
                # Usar st.download_button en lugar de HTML personalizado
                st.download_button(
                    label="üì• Descargar Caracter√≠sticas",
                    data=pickle_data,
                    file_name=f"feature_{unique_id}.pkl",
                    mime="application/octet-stream",
                    help="Descarga el archivo .pkl con las caracter√≠sticas faciales extra√≠das"
                )
                
                # Limpiar archivo temporal
                os.unlink(tmp_file.name)
                
            st.success("‚úÖ Caracter√≠sticas extra√≠das exitosamente!")
            
        except Exception as e:
            st.error(f"‚ùå Ocurri√≥ un error: {str(e)}")

def upload_and_process_image(uploaded_file, pkl_file):
    try:
        _models = FaceNetModels()

        # Guardar el archivo .pkl en una ruta temporal
        with tempfile.NamedTemporaryFile(suffix=".pkl", delete=False) as temp_pkl:
            temp_pkl.write(pkl_file.getvalue())  # Usar getvalue() en lugar de read()
            pkl_file_path = temp_pkl.name

        _models.load_caracteristicas(pkl_file_path)

        # Procesar la imagen subida
        img = Image.open(uploaded_file)

        if img.format == "PNG":
            img = img.convert("RGB")

        # Detectar rostro y obtener embedding
        face_tensor = _models.mtcnn(img)
        
        if face_tensor is None:
            st.error("‚ùå No se detect√≥ ning√∫n rostro en la imagen. Intenta con otra imagen.")
            os.unlink(pkl_file_path)  # Limpiar archivo temporal
            return

        image_embedding = _models.embedding(face_tensor)
        result = _models.Distancia(image_embedding)
        
        if result:
            label, distance = result
            
            # Mostrar resultados en columnas
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.image(img, width=200)
            
            with col2:
                st.success(f"**Persona identificada:** {label}")
                similitud = max(0, int(100 - 17.14 * distance))
                st.metric("Porcentaje de Similitud", f"{similitud}%")
                
                # Agregar indicador visual de confianza
                if similitud > 80:
                    st.success("üéØ Alta confianza")
                elif similitud > 60:
                    st.warning("‚ö†Ô∏è Confianza media")
                else:
                    st.error("‚ùì Baja confianza")
        
        # Limpiar archivo temporal
        os.unlink(pkl_file_path)

    except Exception as e:
        st.error(f"‚ùå Error en el procesamiento: {str(e)}")
        # Asegurar limpieza del archivo temporal
        if 'pkl_file_path' in locals():
            try:
                os.unlink(pkl_file_path)
            except:
                pass

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Reconocimiento Facial",
    page_icon="üë§",
    layout="wide",
    initial_sidebar_state="expanded"
)

# T√≠tulo principal
st.title("üë§ Sistema de Reconocimiento Facial")
st.markdown("---")

# Interface lateral mejorada
with st.sidebar:
    st.header("üìã Informaci√≥n de la App")
    
    with st.expander("‚ÑπÔ∏è C√≥mo usar la aplicaci√≥n"):
        st.markdown("""
        **Esta aplicaci√≥n de reconocimiento facial permite:**
        
        1. **Extraer caracter√≠sticas faciales** de un conjunto de im√°genes
        2. **Guardarlas en un archivo .pkl** (diccionario de caracter√≠sticas)
        3. **Reconocer rostros** comparando con las caracter√≠sticas guardadas
        
        **Para generar caracter√≠sticas:**
        - Selecciona "Generar caracter√≠sticas"
        - Carga im√°genes con nombres como: `Juan.jpg`, `Laura.jpeg`, etc.
        - Las im√°genes deben contener rostros claramente visibles
        
        **Para reconocer rostros:**
        - Selecciona "Cargar diccionario y reconocer"
        - Carga el archivo .pkl generado previamente
        - Carga una imagen para identificar
        """)
    
    st.markdown("---")
    
    option = st.selectbox(
        "üéØ Seleccione una opci√≥n:",
        ("Generar caracter√≠sticas", "Cargar diccionario y reconocer"),
        help="Elige la acci√≥n que deseas realizar"
    )

# Contenido principal
if option == "Generar caracter√≠sticas":
    st.header("üì∏ Generar Caracter√≠sticas Faciales")
    st.markdown("Carga m√∫ltiples im√°genes para extraer las caracter√≠sticas faciales de cada persona.")
    
    uploaded_files = st.file_uploader(
        "Selecciona las im√°genes",
        accept_multiple_files=True,
        type=['jpg', 'jpeg', 'png'],
        help="Carga im√°genes con nombres identificativos (ej: Juan.jpg, Maria.png)"
    )
    
    if uploaded_files:
        st.info(f"üìä {len(uploaded_files)} imagen(es) cargada(s)")
        
        # Mostrar preview de las im√°genes
        if st.checkbox("üëÅÔ∏è Vista previa de im√°genes"):
            cols = st.columns(min(len(uploaded_files), 4))
            for i, file in enumerate(uploaded_files[:4]):  # Mostrar m√°ximo 4
                with cols[i % 4]:
                    img = Image.open(file)
                    st.image(img, caption=file.name, use_column_width=True)
            if len(uploaded_files) > 4:
                st.caption(f"... y {len(uploaded_files) - 4} imagen(es) m√°s")
    
    feature_extraction(uploaded_files)

elif option == "Cargar diccionario y reconocer":
    st.header("üîç Reconocimiento Facial")
    st.markdown("Carga un diccionario de caracter√≠sticas y una imagen para identificar a la persona.")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("1Ô∏è‚É£ Cargar Diccionario")
        pkl_file = st.file_uploader(
            "Selecciona el archivo .pkl",
            type=['pkl'],
            help="Archivo generado en el paso de extracci√≥n de caracter√≠sticas"
        )
    
    with col2:
        st.subheader("2Ô∏è‚É£ Cargar Imagen")
        uploaded_file = st.file_uploader(
            "Selecciona la imagen a reconocer",
            type=['jpg', 'jpeg', 'png'],
            help="Imagen que contiene el rostro a identificar"
        )
    
    if pkl_file and uploaded_file:
        st.markdown("---")
        if st.button("üöÄ Iniciar Reconocimiento", type="primary"):
            with st.spinner("Analizando imagen..."):
                upload_and_process_image(uploaded_file, pkl_file)

# Footer
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>"
    "üí° Desarrollado con Streamlit y FaceNet PyTorch"
    "</div>", 
    unsafe_allow_html=True
)